# Running Open LLMs Locally - The Practical Guide

This repository contains resources for my [Local LLMs via Ollama & LM Studio - The Practical Guide course](https://acad.link/local-llms).

The [/attachments](/attachments/) folder contains slides and other course attachments.

The [/code](/code/) folder contains code examples (the ones from the course).

## Using the Code

If you want to run the code on your system, you must have LM Studio / Ollama up and running (and the Gemma 3 12b QAT model loaded).

You also need Python. 

In addition, you should install the [requests library](https://pypi.org/project/requests/) and [OpenAI SDK](https://github.com/openai/openai-python).